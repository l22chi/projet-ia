{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET IA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des librairies nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from osgeo import gdal\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import colors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le traitement des données géospatiales nous avons besoins d'une librairie spéciale nommée GDAL (geos python lybrary). Cette dernière nécessite une installation particulière.\n",
    "Les commandes ci-dessous sont celles requises pour l'installation de GDAL sur un environnement MAC OS X. Elle correspond à une installattion de GDAL via l'utilitaire de packages brew pour une version de python 3.11 et la version correspondante de GDAL 3.6.4_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !brew install gdal\n",
    "# !pip download GDAL\n",
    "# !tar -xpzf GDAL-3.6.4.tar.gz\n",
    "# !cd GDAL-<version of GDAL>\n",
    "# !python setup.py build_ext --gdal-config /usr/local/Cellar/gdal/3.6.4_1/bin/gdal-config\n",
    "# !python setup.py build\n",
    "# !python setup.py install"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparaation pour l'importation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nom de la time series des données géospatiales (format CSV)\n",
    "dataset = \"time_series.csv\"\n",
    "\n",
    "# mapping des numéros de classes avec les labels et des couleurs (pour le plotting)\n",
    "classe_info = {\n",
    "  'not identified':           {'value':0, 'color': '#000000'},\n",
    "  'soybean':                  {'value':1, 'color': '#ffe32e'},\n",
    "  'maize':                    {'value':2, 'color': '#FF0000'},\n",
    "  'uncultivated soil':        {'value':3, 'color': '#a9b0b0'},\n",
    "  'coffee':                   {'value':4, 'color': '#75781f'},\n",
    "  'beans':                    {'value':5, 'color': '#e5eb34'},\n",
    "  'wheat':                    {'value':6, 'color': '#ff24e5'},\n",
    "  'sorghum':                  {'value':7, 'color': '#a80a96'},\n",
    "  'millet':                   {'value':8, 'color': '#fa73eb'},\n",
    "  'eucalyptus':               {'value':9, 'color': '#c75e0e'},\n",
    "  'pasture':                  {'value':10, 'color': '#fff68f'},\n",
    "  'hay':                      {'value':11, 'color': '#c9cf91'},\n",
    "  'grass':                    {'value':12, 'color': '#12e362'},\n",
    "  'crotalari':                {'value':13, 'color': '#12e362'},\n",
    "  'maize+crotalari':          {'value':14, 'color': '#f77159'},\n",
    "  'cerrado':                  {'value':15, 'color': '#5e2e10'},\n",
    "  'conversion area':          {'value':16, 'color': '#12e0e3'},\n",
    "  'cotton':                   {'value':17, 'color': '#0000FF'},\n",
    "  'ncc':                      {'value':18, 'color': '#12e362'},\n",
    "  'brachiaria':               {'value':19, 'color': '#12e362'},\n",
    "}\n",
    "\n",
    "# récupération des labels\n",
    "classes = {x : y.get('value') for x, y in classe_info.items()}\n",
    "\n",
    "# récupération des couleurs\n",
    "classe_colors = [y.get('color') for x, y in classe_info.items()]\n",
    "\n",
    "# récupération des feaures (EVI)\n",
    "features = ['red', 'nir', 'swir']\n",
    "# récupération du nombre de features\n",
    "n_features = len(features)\n",
    "\n",
    "# définir la taille d'une séquence\n",
    "sequence_size = 30\n",
    "\n",
    "# définition d'un chemin pour la création du dossier de logs pour l'entrainement du modèle\n",
    "model_dir = './logs'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping des numéros de classe avec les labels prédéfinies\n",
    "df['class_name'] = df.apply(lambda row: list(classes.keys())[list(classes.values()).index(row['class'])], axis = 1)\n",
    "# convertir la colonne date en format datetime compréhenssible pour le modèle\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupéraation des sous-times series du dataframe\n",
    "points = df.id.unique()\n",
    "\n",
    "# pour les 7 premières times series récupérées\n",
    "for point in points[:7]:\n",
    "    point_df = df[df['id'] == point]                            # récupérer l'id qui servira de coordonée ordinale\n",
    "    point_df = point_df.sort_values(by=['date'])                # trier par date (de la plus ancienne à la plus récente)\n",
    "    ax = point_df.plot(x='date', y=features, figsize=(20, 5))   # mettre sur l'axe x les dates, l'aaxe y les valeurs de l'IEV (features)\n",
    "\n",
    "    # ploter l'axe\n",
    "    axes1 = plt.gca()\n",
    "    axes2 = axes1.twiny()   \n",
    "    \n",
    "    class_names = point_df['class_name'].tolist()                               # récupérer les labels correspondants à chaque date\n",
    "    axes2.set_xticks(np.arange(len(class_names)))                               # mettre les labels correspondants au niveu du titre\n",
    "    axes2.set_xticklabels(class_names, rotation=50, fontsize=12, minor=False)   # modifier l'affichaage de l'axe des x\n",
    "\n",
    "    # définir les titres des axes\n",
    "    axes1.set_ylabel(\"Features\")\n",
    "    axes1.set_xlabel(\"Image Date\")\n",
    "    axes2.set_xlabel(\"Land Use/Land Cover\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilisation de tensorflow poour le preprocessing des données\n",
    "- Passer les feaatures au format numérique (float) -> X\n",
    "- Passer les labels au format numérique -> y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "# pour chaque time series :\n",
    "for point in points:\n",
    "    point_df = df[df['id'] == point]                # récuéprer la partie du DF correspondant à la time series\n",
    "    point_df = point_df.sort_values(by=['date'])    # trier de la date la plus ancienne à la plus récente\n",
    "    \n",
    "    x_values = point_df[features].to_numpy()        # mettre les features dans un array numpy\n",
    "    y_values = point_df['class'].tolist()           # mettre les labels dans une liste\n",
    "\n",
    "\n",
    "    # utiliser tensorflow pour le preproecssing des array en les passant en array 2D pour le modèle.\n",
    "    x_values = tf.keras.preprocessing.sequence.pad_sequences([x_values], \n",
    "                                                             maxlen=sequence_size, dtype='float32')[0]\n",
    "    y_values = tf.keras.preprocessing.sequence.pad_sequences([y_values], \n",
    "                                                             maxlen=sequence_size, \n",
    "                                                             value=classes.get('not identified'), dtype='float32')[0]\n",
    "    \n",
    "    X.append(x_values)  # ajouter les features preprocessées à X\n",
    "    \n",
    "    # créer un array rempli de 0 et le reemplacer par les valeurs des labels\n",
    "    labels = []\n",
    "    for y_value in y_values:\n",
    "        values = np.zeros(len(classes))\n",
    "        np.put(values, [y_value], [1])\n",
    "        labels.append(values)\n",
    "        \n",
    "    y.append(labels)    # ajouter les labels préprocéssées à y\n",
    "\n",
    "# convertir lese deux listes en array (nous avons donc dess array contenant des 2D array de feeatures et de labels)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# redimensionner l'array des X\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation de dataset en jeu d'entrainement, de validation et de test\n",
    "# utilisation de 80% de la time series pour l'entrainement et de 10% pour la validation et 10% pour le test\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_validation, y_validation, test_size=0.5)\n",
    "\n",
    "print(\"Train: \", len(X_train), \"\\nValidation: \", len(X_validation), \"\\nTest:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle que nous avons décidé d'utiliser est un modèle de deep leaarning de type LSTM :\n",
    "\n",
    "- Parmis les modèles existants dans l'état de l'art, les modèles de type LSTM pour la prédiction de Time Series sembleent être les plus performants.\n",
    "- Nous n'avons pas souhaité utiliser un framework d'entrainement (de type API, comme celle de PyTorch ou TF) car nous avons pensé avoir les connaissances suffisantes pour définir nous même l'aarchitecture de notre modèle.\n",
    "- Ainsi nous avons pu meettre en oeuvre une structure de modèle de deep learning en restant simple, cee qui nous permet de contrôler nos outputs, de faire des modifications de structures si nécessaires et d'avoir une idée des outputs à chaque fin de layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(n_classes, sequence_size, n_features):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(200, input_shape=(sequence_size, n_features)))\n",
    "    \n",
    "    model.add(tf.keras.layers.RepeatVector(sequence_size))\n",
    "    \n",
    "    model.add(tf.keras.layers.LSTM(200, activation='relu', return_sequences=True))\n",
    "    \n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(100, activation='relu')))\n",
    "\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_classes)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "              \n",
    "model = LSTM(n_classes=len(classes), sequence_size=sequence_size, n_features=n_features)\n",
    "              \n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, to_file='model.png') # enregistrement de la structure au format png"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramétrage d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"{dir}/model.ckpt\".format(dir=model_dir) # chemin d'enregistrement des checkpointt pour reprendre l'entrainement en cas d'arret\n",
    "\n",
    "latest = tf.train.latest_checkpoint(model_dir)             # reprendre l'entrainement à partir du dernier checkpoint trouvé\n",
    "\n",
    "if latest:\n",
    "    model.load_weights(latest)   # si un checkpoint est trouvé, charger les poids enregistrés à ce chekpoint\n",
    "\n",
    "# définition du checkpoint\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, save_best_only=True)\n",
    "# définition de l'early stopping pour arrêter le modèle si la loss \"stagne\" - \"atteint une limite\" - \"minimum absolu\" \n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', \n",
    "                                            baseline=None, restore_best_weights=True)\n",
    "\n",
    "# définition des calllbacks (checkpoint  + early stopping)\n",
    "callbacks = [cp_callback, es_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100        # nombre d'epochs lors de l'entrainement\n",
    "batch_size = 128    # batch_size volontairement haut afin d'éviter l'over-fitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train, y=y_train, \n",
    "          validation_data=(X_validation, y_validation),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=callbacks, use_multiprocessing=False, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats de l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichag de la courbe de précision en fonction des epochs\n",
    "fig, ax = plt.subplots(2,1, figsize=(15, 10))\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "# affichag de la courbe de loss en fonction des epochs\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage de la loss et de l'accuracy sur l'ensemble de test pour définir la performance finale de notre modèle\n",
    "model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5') # enregistrements des poids de notre modèle pour le réutiliser dans l'étape de prédiction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction sur des données géospatiales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement de la donnée à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'image_2019-10-01_2020-10-01.tif'          # donnée géospatiale\n",
    "predicted_path = 'predicted_2019-10-01_2020-10-01.tif'  # nom du fichier de la donnée prédite\n",
    "data_source = gdal.Open(image_path)                     # chargement de la donnée\n",
    "image = data_source.ReadAsArray()                       # lire la donnée en array\n",
    "image.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesssing de la donnée à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_image = image.reshape(image.shape[0],\n",
    "                           image.shape[1] * image.shape[2])                             # redimensionner l'array pour le lire dans le modèle\n",
    "\n",
    "flat_image = flat_image.transpose()                                                     # inverser l'array\n",
    "\n",
    "flat_image = flat_image.reshape((flat_image.shape[0],                                   # redimensionnement\n",
    "                                 int(flat_image.shape[1] / n_features), n_features))\n",
    "\n",
    "# appliquer le même preprocessing que pour l'entrainement\n",
    "flat_image = np.array(flat_image).astype(float)                                         \n",
    "print(flat_image.shape)\n",
    "\n",
    "padded_image = tf.keras.preprocessing.sequence.pad_sequences(flat_image, maxlen=sequence_size, dtype='float32')\n",
    "padded_image.shape\n",
    "\n",
    "# normaliser les valeurs de l'array\n",
    "rescaled_image = padded_image / 10000.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancer l'inférence sur la donnée à l'aide du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_predicted = model.predict(rescaled_image, batch_size=1024)\n",
    "flat_predicted.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparer les résultats de la prédiction pour l'affichage du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# préparation des labels\n",
    "flat_labels = np.argmax(flat_predicted, axis=2)\n",
    "print(flat_predicted.shape, '-->', flat_labels.shape)\n",
    "\n",
    "print(flat_labels.shape, flat_image.shape[1])\n",
    "\n",
    "valid_flat_labels = flat_labels[:,-flat_image.shape[1]:]\n",
    "print(valid_flat_labels.shape)\n",
    "\n",
    "# préparation de l'image\n",
    "predicted_image = valid_flat_labels.reshape((image.shape[1], image.shape[2], valid_flat_labels.shape[-1]))\n",
    "print(predicted_image.shape)\n",
    "\n",
    "predicted_image = predicted_image[:, :, predicted_image.shape[-1] - image.shape[0]:]\n",
    "predicted_image.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enregistrement des résultats au format TIF (donnée géospatiale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = data_source.GetDriver()\n",
    "output_dataset = driver.Create(predicted_path,\n",
    "                               predicted_image.shape[1],\n",
    "                               predicted_image.shape[0],\n",
    "                               predicted_image.shape[-1],\n",
    "                               gdal.GDT_Byte,\n",
    "                               ['COMPRESS=DEFLATE'])\n",
    "output_dataset.SetGeoTransform(data_source.GetGeoTransform())\n",
    "output_dataset.SetProjection(data_source.GetProjection())\n",
    "\n",
    "for band_id in range(predicted_image.shape[-1]):\n",
    "    band_data = predicted_image[:, : , band_id]        \n",
    "    output_dataset.GetRasterBand(band_id + 1).WriteArray(band_data, 0, 0)\n",
    "output_dataset.FlushCache()\n",
    "del output_dataset\n",
    "print(\"Completed!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de la prédiction pour l'affichage d'un résultat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement de la donnée géospatiale (TIF) prédite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = gdal.Open(predicted_path)\n",
    "image = data_source.ReadAsArray()\n",
    "image.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction de la vidéo pour compiler les images TIF de données géospatiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour charger un fichire et jouer la vidéo dans un format html\n",
    "\n",
    "def play(filename):\n",
    "    html = ''\n",
    "    video = open(filename,'rb').read()\n",
    "    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n",
    "    html += '<video width=1000 controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src \n",
    "    return HTML(html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supperposer la prédiction avec la légende des labels sur la vidéo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# préparer la structure du plot\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "ims = []\n",
    "\n",
    "# récupérer les couleurs des classes (labels)\n",
    "cmap = colors.ListedColormap(classe_colors) \n",
    "\n",
    "# pour chaque morceaux de l'image (TIF) prédite\n",
    "    # afficher l'image prédite (image + supperposition des labels et des couleurs)\n",
    "    # ajoutter la superposition à la liste imss\n",
    "for band in image:\n",
    "    im = ax.imshow(band, vmin=0, vmax=len(classe_colors)-1, cmap=cmap, animated=True)\n",
    "    ims.append([im])\n",
    "\n",
    "# créer une animation dont les frames sont les images de la liste ims\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, blit=True, repeat_delay=1000)\n",
    "\n",
    "# ajouter les labels dans la légente avec la coloration par classe\n",
    "patches = list(map(lambda item: mpatches.Patch(color=item[1].get('color'), label=item[0]), classe_info.items() ))\n",
    "plt.legend(handles=patches, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "output = 'predicted.mp4' # nom du fichire d'enregistrement\n",
    "ani.save(output)         # enregistrer le résultat au format mp4\n",
    "\n",
    "play(output)             # jouer le résultat final dans un cadre html (pour le notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet-ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
